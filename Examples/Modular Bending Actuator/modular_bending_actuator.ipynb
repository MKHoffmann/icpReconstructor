{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular Bending Actuator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "The dataset is available for this example and can be downloaded from  \n",
    "Schindler and de Payrebrune [1] by CC BY. Copy the contents of the  \n",
    "`data.zip` inside this folder, such that  a `calibration` and a  \n",
    "`dataset_02` folder exist inside this directory.  \n",
    "\n",
    "Since this example requires some modifications to the source base of  \n",
    "icpReconstructor. It is recommended to generate a fresh virtual  \n",
    "environment using  \n",
    "```bash\n",
    "python -m venv .venv\n",
    "```  \n",
    "in the main directory of the icpReconstructor repository. After  \n",
    "activation of the virtual environment using  \n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "```\n",
    "the modified local icpReconstructor can be installed using  \n",
    "```bash\n",
    "pip install -e .\n",
    "``` \n",
    "If the install fails due to the line `version='{{VERSION_PLACEHOLDER}}'`  \n",
    "in `setup.py`, replace it with `version='0.0.1'`.\n",
    "\n",
    "This example requires additionally the installation of OpenCV and   \n",
    "matplotlib. This can be done via  \n",
    "```bash\n",
    "pip install opencv-python matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary dependencies for this example. Some   \n",
    "methods which are required by this example have been placed in the  \n",
    "`utils.py` file for readability of this file. Tinkering with these  \n",
    "methods is still possible, but not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "from icpReconstructor import TorchCurveEstimator\n",
    "\n",
    "from icpReconstructor.extensions import (\n",
    "    Module,\n",
    "    ModularBendingActuator)\n",
    "\n",
    "from utils import (\n",
    "    load_calibration_parameters,\n",
    "    load_images,\n",
    "    preprocess_images,\n",
    "    compute_projected_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following settings are global and should only be changed with  \n",
    "caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIRECTORY = Path(\"./dataset_02/raw\")\n",
    "CALIBRATION_DIRECTORY = Path(\"./calibration\")\n",
    "\n",
    "# Number of cameras in the system\n",
    "NUMBER_OF_CAMERAS = 2\n",
    "# Schedule entry index (from dataset)\n",
    "SCHEDULE_ENTRY_INDEX = 39\n",
    "\n",
    "# Thresholds used for the binary images\n",
    "THRESHOLD_MINIMUM_R = 200.0 / 255.0\n",
    "THRESHOLD_MAXIMUM_G = 190.0 / 255.0\n",
    "THRESHOLD_MAXIMUM_B = 140.0 / 255.0\n",
    "\n",
    "# Force the usage of the CPU\n",
    "USE_CPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup torch device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a CUDA-Device is available, we will use this device unless explicitly  \n",
    "prohibit by the `USE_CPU` flag above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() and not USE_CPU else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "# Print default device\n",
    "display(f\"Using device: {torch.get_default_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load camera calibration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the camera calibration parameters from the `calibration` folder.  \n",
    "The calibration data needed in this example contains the camera matrix,  \n",
    "projection matrix and distortion coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the calibration parameters of the cameras\n",
    "calibration_parameters = load_calibration_parameters(\n",
    "    CALIBRATION_DIRECTORY,\n",
    "    NUMBER_OF_CAMERAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following snippet, we load the images from the dataset and    \n",
    "preprocess them to binary images using a color value threshold. For  \n",
    "a different entry changed the `SCHEDULE_ENTRY_INDEX` in the global  \n",
    "settings above. Note that this operation can take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames for target images\n",
    "image_filenames = []\n",
    "for camera_index in range(NUMBER_OF_CAMERAS):\n",
    "    image_filename = str(\n",
    "        Path(DATA_DIRECTORY) / \n",
    "        f\"CROPPED_C{camera_index + 1}_E{SCHEDULE_ENTRY_INDEX}.png\")\n",
    "\n",
    "    image_filenames.append(image_filename)\n",
    "        \n",
    "# Load images for annotation\n",
    "raw_images = load_images(image_filenames)\n",
    "\n",
    "# Preprocess images with the given color value thresholds\n",
    "target_images, target_image_indices = preprocess_images(\n",
    "    raw_images,\n",
    "    THRESHOLD_MINIMUM_R,\n",
    "    THRESHOLD_MAXIMUM_G,\n",
    "    THRESHOLD_MAXIMUM_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the raw images and the binarized images with the thresholds from   \n",
    "the global settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "figure = pyplot.figure()\n",
    "gridspec = figure.add_gridspec(2, 2)\n",
    "ax00 = figure.add_subplot(gridspec[0, 0])\n",
    "ax01 = figure.add_subplot(gridspec[0, 1])\n",
    "ax10 = figure.add_subplot(gridspec[1, 0])\n",
    "ax11 = figure.add_subplot(gridspec[1, 1])\n",
    "axes = [ax00, ax01, ax10, ax11]\n",
    "\n",
    "ax00.imshow(raw_images[0])\n",
    "ax01.imshow(raw_images[1])\n",
    "ax10.imshow(target_images[0])\n",
    "ax11.imshow(target_images[1])\n",
    "\n",
    "ax00.set_title(\"First Camera (Raw)\")\n",
    "ax01.set_title(\"Second Camera (Raw)\")\n",
    "ax10.set_title(\"First Camera (Binarized)\")\n",
    "ax11.set_title(\"Second Camera (Binarized)\")\n",
    "\n",
    "for axis in axes:\n",
    "    axis.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following snippet the reconstruction of the backbone is performed.  \n",
    "The reconstruction is based on the method described in Hoffmann et al. [2]  \n",
    "and on the modifications described in Schindler and de Payrebrune [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to play around with\n",
    "# Slender or volumetric model\n",
    "slender = False\n",
    "# Curvature degree\n",
    "curvature_degree = 3\n",
    "# Weight factor between pixel and backbone loss\n",
    "w = 0.1\n",
    "# Number of estimate points along backbone for each actuator\n",
    "number_of_steps: int = 10\n",
    "# Learning rates \n",
    "learning_rates = (\n",
    "    1.0,  # ... for the curvature coefficients\n",
    "    0.01, # ... for the elongation coefficients\n",
    "    0.01) # ... for the base position\n",
    "# Distance norm for the loss function\n",
    "distance_norm = 2\n",
    "# Number of epochs\n",
    "epochs = 40\n",
    "# Batch size in pixels\n",
    "batch_size = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bending actuator with a single module. We set the initial base  \n",
    "position to a good guess and the base rotation to 150° as it is fixed by  \n",
    "the base plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bending Actuator with a single module using default parameters\n",
    "module = Module()\n",
    "modules = [ module ]\n",
    "\n",
    "# Initial guess for the base position and rotation\n",
    "base_position = torch.tensor([0.026, 0.092, 0.37])\n",
    "base_rotation = torch.tensor(150) # degrees\n",
    "\n",
    "# Create the bending actuator\n",
    "bending_actuator = ModularBendingActuator(\n",
    "    modules,\n",
    "    base_position=base_position,\n",
    "    base_rotation=base_rotation,\n",
    "    slender=slender,\n",
    "    curvature_degree=curvature_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the curve estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the bending actuator\n",
    "L = bending_actuator.l.sum()\n",
    "\n",
    "# Curve Estimator\n",
    "estimator = TorchCurveEstimator(\n",
    "    bending_actuator,\n",
    "    calibration_parameters, \n",
    "    l=L,\n",
    "    w=w, \n",
    "    n_steps=number_of_steps, \n",
    "    dist_norm=distance_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the optimizer and the learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "learning_rates = learning_rates\n",
    "parameter_groups = [\n",
    "    { \"params\": [], \"lr\": lr } for lr in learning_rates ]\n",
    "parameter_map = {\n",
    "    \"ux.u_p\": 0,\n",
    "    \"uy.u_p\": 0,\n",
    "    \"la.u_p\": 1,\n",
    "    \"base_position\": 2,\n",
    "}\n",
    "\n",
    "for name, parameter in bending_actuator.named_parameters():\n",
    "    parameter_group_index = parameter_map.get(name, 0)\n",
    "    parameter_groups[parameter_group_index][\"params\"].append(parameter)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    parameter_groups, \n",
    "    learning_rates[1], \n",
    "    weight_decay=0)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer=optimizer,\n",
    "    start_factor=1.0,\n",
    "    end_factor=0.5,\n",
    "    total_iters=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = pyplot.figure(figsize=(4, 4))\n",
    "display_handle = display(\"\", display_id=True)\n",
    "\n",
    "gridspec = figure.add_gridspec(1, 1)\n",
    "axis_loss = figure.add_subplot(gridspec[0, 0])\n",
    "\n",
    "def update(_):\n",
    "    axis_loss.clear()\n",
    "    axis_loss.grid()\n",
    "    axis_loss.set_title(\"Loss\")\n",
    "    axis_loss.set_xlabel(\"Epoch\")\n",
    "    axis_loss.set_ylabel(\"Loss\")\n",
    "    axis_loss.set_xlim(0, epochs)\n",
    "\n",
    "    axis_loss.plot(estimator.loss_history, color=\"blue\")\n",
    "    \n",
    "    # Update the already printed figure\n",
    "    display_handle.update(figure)\n",
    "\n",
    "# Set callback for the post-epoch\n",
    "estimator.post_epoch_cb = [update]\n",
    "\n",
    "# Fit the backbone\n",
    "# NOTE: We need to explicitly set the device here since the numpy to\n",
    "#       torch conversion does not follow the set default device.\n",
    "loss_history = estimator.fit(\n",
    "    pixel_list=target_image_indices, \n",
    "    optimizer=optimizer, \n",
    "    scheduler=lr_scheduler,\n",
    "    n_iter=epochs, \n",
    "    batch_size=batch_size,\n",
    "    device=torch.get_default_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the reconstructed backbone\n",
    "Finally we plot the reconstructed backbone as blue dashed line and the  \n",
    "estimate points as white markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length discretization\n",
    "s_values = estimator.s_val\n",
    "\n",
    "# Solve for the backbone\n",
    "p_values, R_values = bending_actuator.solve_backbone(s_values)\n",
    "\n",
    "# Solve for the chamber backbones\n",
    "estimate_points = bending_actuator.generate_estimate_points(\n",
    "    s_values, p_values, R_values)\n",
    "\n",
    "# Detach estimate points points for further computation in the \n",
    "# visualization stage\n",
    "estimate_points = estimate_points.detach()\n",
    "\n",
    "# Backbone\n",
    "backbone = bending_actuator.from_actuator_space_to_world_space(p_values)\n",
    "backbone = backbone.detach()\n",
    "\n",
    "# Project basepoint to images\n",
    "#  Detach \n",
    "base_position = bending_actuator.base_position.detach()\n",
    "#  Unsqueeze because we need the batched form for points\n",
    "base_position = base_position.unsqueeze(0)\n",
    "\n",
    "# Convert the base position to image space to see if it fits the image\n",
    "projected_base_position = compute_projected_points(\n",
    "    base_position, calibration_parameters).squeeze(1)\n",
    "\n",
    "# Project estimate points to images\n",
    "projected_estimate_points = compute_projected_points(\n",
    "    estimate_points, calibration_parameters)\n",
    "\n",
    "# Project bacbkone to images\n",
    "projected_backbone = compute_projected_points(\n",
    "    backbone, calibration_parameters)\n",
    "\n",
    "for camera_index, image in enumerate(raw_images):\n",
    "    # Create figure\n",
    "    figure = pyplot.figure()\n",
    "    axis = figure.add_subplot()\n",
    "\n",
    "    axis.imshow(image, aspect=\"auto\")\n",
    "    axis.set_axis_off()\n",
    "\n",
    "    # Plot settings\n",
    "    scatter_settings = {\n",
    "        \"marker\": \"P\",\n",
    "        \"edgecolors\": \"black\"\n",
    "    }\n",
    "\n",
    "    axis.plot(\n",
    "        projected_backbone[camera_index, :, 0],\n",
    "        projected_backbone[camera_index, :, 1],\n",
    "        linestyle=\"--\",\n",
    "        color=\"blue\",\n",
    "        label=\"Backbone\")\n",
    "\n",
    "    axis.scatter(\n",
    "        projected_base_position[camera_index, 0], \n",
    "        projected_base_position[camera_index, 1], \n",
    "        label=\"Base Position\", c=\"blue\", **scatter_settings)\n",
    "\n",
    "    axis.scatter(\n",
    "        projected_estimate_points[camera_index, :, 0],\n",
    "        projected_estimate_points[camera_index, :, 1],\n",
    "        label=\"Estimate Points\", c=\"white\", **scatter_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgement\n",
    "\n",
    "Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research   \n",
    "Foundation) – 501861263 – SPP2353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Schindler, L. and de Payrebrune, K.: Data for \"Image-based Backbone  \n",
    "Reconstruction for Non-Slender Soft Robots\". Zenodo, 2024.  \n",
    "DOI: 10.5281/zenodo.11352738\n",
    "\n",
    "[2] M. K. Hoffmann, J. Mühlenhoff, Z. Ding, T. Sattel and K. Flaßkamp.  \n",
    "An iterative closest point algorithm for marker-free 3D shape  \n",
    "registration of continuum robots. arXiv preprint, (2024).   \n",
    "DOI: 10.48550/arXiv.2405.15336\n",
    "\n",
    "[3] Schindler, L. and de Payrebrune, K.: Image-based backbone  \n",
    "reconstruction for non-slender soft robots. Proceedings in Applied  \n",
    "Mathematics, 2024. (Submitted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
